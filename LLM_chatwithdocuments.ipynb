{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPHal3pmqO793BpVNoQhiTF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeepvaranasi/LLMs-ChatWithDocuments/blob/main/LLM_chatwithdocuments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Build LLMs based file-reading assistant that can quickly extract, locate, and summarize information from documents"
      ],
      "metadata": {
        "id": "OsaumahTxGwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation\n"
      ],
      "metadata": {
        "id": "ojsIOivH3iOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Installing LLM libraries"
      ],
      "metadata": {
        "id": "trQ1vYEmxXQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install langchain faiss-cpu unstructured\n",
        "# !pip -q install openai tiktoken\n",
        "# !pip -q install pytesseract pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hzLEpFAxWVC",
        "outputId": "2d0314d0-0f5d-406e-fb81-11c6d236ecf9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing libraries"
      ],
      "metadata": {
        "id": "6UeYnuiSxKqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_taHEKwcwR78"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from langchain.document_loaders.image import UnstructuredImageLoader\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Detecting Documents\n"
      ],
      "metadata": {
        "id": "h88Dt_D43aIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from filetype import guess\n",
        "\n",
        "def detect_document_type(document_path):\n",
        "\n",
        "    guess_file = guess(document_path)\n",
        "    file_type = \"\"\n",
        "    image_types = ['jpg', 'jpeg', 'png', 'gif']\n",
        "\n",
        "    if(guess_file.extension.lower() == \"pdf\"):\n",
        "        file_type = \"pdf\"\n",
        "\n",
        "    elif(guess_file.extension.lower() in image_types):\n",
        "        file_type = \"image\"\n",
        "\n",
        "    else:\n",
        "        file_type = \"unkown\"\n",
        "\n",
        "    return file_type\n",
        ""
      ],
      "metadata": {
        "id": "w4ZOQWyk3eYR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_cisco_annualreport_2022 = \"/content/cisco-annual-report-subset-2022.pdf\"\n",
        "img_machinelearning = \"/content/Advantages-and-disadvantages-of-machine-learning-methods.png\"\n",
        "\n",
        "print(f\"Cisco Report - Document Type : {detect_document_type(pdf_cisco_annualreport_2022)}\")\n",
        "print(f\"Machine Learning Information - Document Type : {detect_document_type(img_machinelearning)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9VPuqYR3qJK",
        "outputId": "8be13e9a-b6ca-48b0-c150-4d5dd7bb8576"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cisco Report - Document Type : pdf\n",
            "Machine Learning Information - Document Type : image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.image import UnstructuredImageLoader\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "def extract_file_content(file_path):\n",
        "\n",
        "    file_type = detect_document_type(file_path)\n",
        "\n",
        "    if(file_type == \"pdf\"):\n",
        "        loader = UnstructuredFileLoader(file_path)\n",
        "\n",
        "    elif(file_type == \"image\"):\n",
        "        loader = UnstructuredImageLoader(file_path)\n",
        "\n",
        "    documents = loader.load()\n",
        "    documents_content = '\\n'.join(doc.page_content for doc in documents)\n",
        "\n",
        "    return documents_content"
      ],
      "metadata": {
        "id": "MKyBr5ib4ILg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install unstructured==0.7.12"
      ],
      "metadata": {
        "id": "yIoTPQLq5YjC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDCdSMgT6UPL",
        "outputId": "3eeb21c4-a942-48b4-94a4-2410f7d9e573"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdCKP3d86ZI4",
        "outputId": "3f702c08-f370-4576-ef57-9834c734b7dd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "\n",
        "try:\n",
        "  from PIL import Image\n",
        "except ImportError:\n",
        "  import Image"
      ],
      "metadata": {
        "id": "DdqLfx8n6dVv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cisco_content = extract_file_content(pdf_cisco_annualreport_2022)\n",
        "ml_content = extract_file_content(img_machinelearning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XYB9zgw4O4s",
        "outputId": "056cab32-821b-417f-c45d-ece362f42f4e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_characters = 400\n",
        "\n",
        "print(f\"First {nb_characters} Characters of the Report : \\n{cisco_content[:nb_characters]}...\")\n",
        "print(\" \"*25)\n",
        "print(\"---\"*25)\n",
        "print(\" \"*25)\n",
        "print(f\"First {nb_characters} Characters of the ML image :\\n {ml_content[:nb_characters]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLptVt556yFb",
        "outputId": "25d2b7f3-53d4-4c12-e0b7-2872310ccdb6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 400 Characters of the Report : \n",
            "Our purpose\n",
            "\n",
            "Powering an inclusive future for all\n",
            "\n",
            "Cisco’s efforts to fulfill our Purpose to Power an Inclusive Future for All are organized into three ESG pillars. From the technology that helps securely power the world’s connectivity (Power), to driving fairness, inclusion, and equitable opportunity (Inclusive), and helping to ensure a sustainable and regenerative planet (Future).\n",
            "\n",
            "Power For alm...\n",
            "                         \n",
            "---------------------------------------------------------------------------\n",
            "                         \n",
            "First 400 Characters of the ML image :\n",
            " Name\n",
            "\n",
            "type\n",
            "\n",
            "Advantages\n",
            "\n",
            "Disadvantages\n",
            "\n",
            "SVM\n",
            "\n",
            "Supervised Learning,\n",
            "\n",
            "Kemel methods\n",
            "\n",
            "\n",
            "\n",
            "based\n",
            "\n",
            "No probability Good for high dimensional data Less risk of over-fitting\n",
            "\n",
            "Difficult to choose a proper kernel function Long training time\n",
            "\n",
            "Difficult to understand and interpret the final model, variable weights and individual impact\n",
            "\n",
            "does not perform very well, when the data set has more noise\n",
            "\n",
            "Logic regressio...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "_WKPi3vZ7UrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")"
      ],
      "metadata": {
        "id": "LlEbj5LQ7OL4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cisco_content_chunks = text_splitter.split_text(cisco_content)\n",
        "ml_content_chunks = text_splitter.split_text(ml_content)\n",
        "\n",
        "print(f\"# Chunks in Research Paper: {len(cisco_content_chunks)}\")\n",
        "print(f\"# Chunks in Article Document: {len(ml_content_chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKpRFTIV7dem",
        "outputId": "1d69036f-f6d8-45b0-ca00-d113e10fab59"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Chunks in Research Paper: 10\n",
            "# Chunks in Article Document: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "OcK2MwhR7dh1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def get_doc_search(text_splitter):\n",
        "\n",
        "    return FAISS.from_texts(text_splitter, embeddings)"
      ],
      "metadata": {
        "id": "1b6CgyGf7dmX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat with Documents"
      ],
      "metadata": {
        "id": "Iohz8NV8BTDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "chain = load_qa_chain(OpenAI(), chain_type = \"map_rerank\",\n",
        "                      return_intermediate_steps=True)\n",
        "\n",
        "def chat_with_file(file_path, query):\n",
        "\n",
        "    file_content = extract_file_content(file_path)\n",
        "    file_splitter = text_splitter.split_text(file_content)\n",
        "\n",
        "    document_search = get_doc_search(file_splitter)\n",
        "    documents = document_search.similarity_search(query)\n",
        "\n",
        "    results = chain({\n",
        "                        \"input_documents\":documents,\n",
        "                        \"question\": query\n",
        "                    },\n",
        "                    return_only_outputs=True)\n",
        "    results = results['intermediate_steps'][0]\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "-w2VN8hJ97hx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the purpose of Cisco?\"\n",
        "\n",
        "results = chat_with_file(pdf_cisco_annualreport_2022, query)\n",
        "\n",
        "answer = results[\"answer\"]\n",
        "confidence_score = results[\"score\"]\n",
        "\n",
        "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0u-5iPA-Ajj",
        "outputId": "4c516a0f-3556-4551-cd6f-d81e95dc2bae"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:303: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  Cisco's purpose is to ensure that their products are made responsibly, consistent with Cisco's values, and that their suppliers uphold their standards for labor, health and safety, environment, and ethics.\n",
            "\n",
            "Confidence Score: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the document about?\"\n",
        "\n",
        "results = chat_with_file(img_machinelearning, query)\n",
        "\n",
        "answer = results[\"answer\"]\n",
        "confidence_score = results[\"score\"]\n",
        "\n",
        "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUAnC3h3-ADH",
        "outputId": "4b76db99-3c13-4b7a-bcb2-bdaa5fdae19e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-rEDbr2bcinJhQrX6MsqYwwag on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:303: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  This document is about Deep Learning, Bayesian Learning, Monte Carlo, and Reinforcement Teaming and their respective advantages and disadvantages.\n",
            "\n",
            "Confidence Score: 100\n"
          ]
        }
      ]
    }
  ]
}